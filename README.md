<p align="center">
  <img src="https://user-images.githubusercontent.com/4206926/49877604-10457580-fe26-11e8-92d7-cd876c4f6454.png" width=350/>
</p>

#

[![Workflow](https://github.com/nccgroup/ScoutSuite/workflows/CI%20Workflow/badge.svg)](https://github.com/nccgroup/ScoutSuite/actions)
[![CodeCov](https://codecov.io/gh/nccgroup/ScoutSuite/branch/master/graph/badge.svg)](https://codecov.io/gh/nccgroup/ScoutSuite)

[![PyPI version](https://badge.fury.io/py/ScoutSuite.svg)](https://badge.fury.io/py/ScoutSuite)
[![PyPI downloads](https://img.shields.io/pypi/dm/scoutsuite)](https://img.shields.io/pypi/dm/scoutsuite)
[![Docker Hub](https://img.shields.io/badge/Docker%20Hub-rossja%2Fncc--scoutsuite-blue)](https://hub.docker.com/r/rossja/ncc-scoutsuite/)
[![Docker Pulls](https://img.shields.io/docker/pulls/rossja/ncc-scoutsuite.svg?style=flat-square)](https://hub.docker.com/r/rossja/ncc-scoutsuite/)

## Description

Scout Suite is an open source multi-cloud security-auditing tool, which enables security posture assessment of cloud environments. Using the APIs exposed by cloud providers, Scout Suite gathers configuration data for manual inspection and highlights risk areas. Rather than going through dozens of pages on the web consoles, Scout Suite presents a clear view of the attack surface automatically.

Scout Suite was designed by security consultants/auditors. It is meant to provide a point-in-time security-oriented view of the cloud account it was run in. Once the data has been gathered, all usage may be performed offline.

The project team can be contacted at <scoutsuite@nccgroup.com>.

### Cloud Provider Support

The following cloud providers are currently supported:

- Amazon Web Services
- Microsoft Azure
- Google Cloud Platform
- Alibaba Cloud (alpha)
- Oracle Cloud Infrastructure (alpha)
- Kubernetes clusters on a cloud provider (alpha)
- DigitalOcean Cloud (alpha)

## Installation

Refer to the [wiki](https://github.com/nccgroup/ScoutSuite/wiki/Setup).

## Usage

Scout Suite is run through the CLI:

![Running Scout Suite](https://user-images.githubusercontent.com/13310971/78389085-22659d00-75b0-11ea-9f22-ea6fcaa6a1cd.gif)

Once this has completed, it will generate an HTML report including findings and Cloud account configuration:

![Scout Suite Report](https://user-images.githubusercontent.com/13310971/77861662-342bf680-71e4-11ea-8eed-ccaeb78c5f45.gif)

The above report was generated by running Scout Suite against https://github.com/nccgroup/sadcloud.

Additional information can be found in the [wiki](https://github.com/nccgroup/ScoutSuite/wiki). 
There are also a number of handy [tools](https://github.com/nccgroup/ScoutSuite/tree/master/tools) for automation of common tasks.

---

# Jules Just-Works Pack

- Extract this into your repo root:
  ```bash
  bash jules-pack-clean.sfx.sh .
  ```
- At the top of EVERY Jules task, paste:
  ```bash
  bash scripts/jules_preamble.sh
  ```

---

## Development Setup

This project uses a `Makefile` to simplify common development tasks.

1.  **Install dependencies:**
    ```bash
    make install
    ```

2.  **Run database migrations:**
    ```bash
    python manage.py migrate
    ```

### Running the Application

1.  **Start the Django development server:**
    ```bash
    make run-server
    ```

2.  **Start the Celery worker:**
    In a separate terminal, run:
    ```bash
    make run-worker
    ```
    You will also need a Redis server running on `localhost:6379`. See the Docker Compose section for an easy way to run Redis.

### Running Tests and Checks

-   Run the test suite: `make test`
-   Run the linter: `make lint`
-   Run the security scanner: `make security-check`
-   Run all checks: `make all-checks`

---

## Running with Docker

The easiest way to get the full application stack running is with Docker Compose.

1.  **Create a `.env` file:**
    Copy the `.env.example` file to `.env` and fill in the required environment variables, especially `SECRET_KEY`.

2.  **Build and start the services:**
    ```bash
    docker-compose up --build
    ```
    This will start the web server, the celery worker, and a redis instance.

### Usage

You can interact with the application through the REST API.

1.  **Create a Cloud Provider:**
    ```bash
    curl -X POST http://localhost:8000/api/cloudproviders/ -H "Content-Type: application/json" -d '{"name": "Amazon Web Services", "code": "aws"}'
    ```

2.  **Create an Account:**
    ```bash
    curl -X POST http://localhost:8000/api/accounts/ -H "Content-Type: application/json" -d '{"name": "My AWS Account", "provider": 1, "credentials": {"aws_access_key_id": "YOUR_KEY", "aws_secret_access_key": "YOUR_SECRET"}}'
    ```

3.  **Trigger a Scan:**
    ```bash
    curl -X POST http://localhost:8000/api/accounts/1/scan/
    ```

4.  **Check Scan Status:**
    ```bash
    curl http://localhost:8000/api/scans/1/
    ```

5.  **View Findings:**
    ```bash
    curl http://localhost:8000/api/findings/
    ```

6.  **Manage RuleSets:**
    ```bash
    # Create a new ruleset
    curl -X POST http://localhost:8000/api/rulesets/ -H "Content-Type: application/json" -d '{"name": "My Custom Ruleset"}'

    # List rulesets
    curl http://localhost:8000/api/rulesets/
    ```

7.  **Trigger a Scan with a Custom Configuration:**
    ```bash
    curl -X POST http://localhost:8000/api/accounts/1/scan/ -H "Content-Type: application/json" -d '{"configuration": {"ruleset": "My Custom Ruleset"}}'
    ```
